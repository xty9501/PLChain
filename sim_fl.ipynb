{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#import library\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np ; np.random.seed(sum(map(ord, \"aesthetics\")))\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_curve, roc_auc_score, auc, accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit,train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize, StandardScaler, MinMaxScaler\n",
    "\n",
    "import seaborn\n",
    "seaborn.set_context('notebook')\n",
    "seaborn.set_style(style='darkgrid')\n",
    "\n",
    "#from pprint import pprint\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function for evaluation reports\n",
    "def get_eval1(clf, X,y):\n",
    "    # Cross Validation to test and anticipate overfitting problem\n",
    "    scores1 = cross_val_score(clf, X, y, cv=2, scoring='accuracy')\n",
    "    scores2 = cross_val_score(clf, X, y, cv=2, scoring='precision')\n",
    "    scores3 = cross_val_score(clf, X, y, cv=2, scoring='recall')\n",
    "    scores4 = cross_val_score(clf, X, y, cv=2, scoring='roc_auc')\n",
    "\n",
    "    # The mean score and standard deviation of the score estimate\n",
    "    print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std()))\n",
    "    print(\"Cross Validation Precision: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std()))\n",
    "    print(\"Cross Validation Recall: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std()))\n",
    "    print(\"Cross Validation roc_auc: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std()))\n",
    "\n",
    "    return\n",
    "\n",
    "def get_eval2(clf, X_train, y_train,X_test, y_test):\n",
    "    # Cross Validation to test and anticipate overfitting problem\n",
    "    scores1 = cross_val_score(clf, X_test, y_test, cv=2, scoring='accuracy')\n",
    "    scores2 = cross_val_score(clf, X_test, y_test, cv=2, scoring='precision')\n",
    "    scores3 = cross_val_score(clf, X_test, y_test, cv=2, scoring='recall')\n",
    "    scores4 = cross_val_score(clf, X_test, y_test, cv=2, scoring='roc_auc')\n",
    "\n",
    "    # The mean score and standard deviation of the score estimate\n",
    "    print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std()))\n",
    "    print(\"Cross Validation Precision: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std()))\n",
    "    print(\"Cross Validation Recall: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std()))\n",
    "    print(\"Cross Validation roc_auc: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std()))\n",
    "\n",
    "    return\n",
    "\n",
    "# Function to get roc curve\n",
    "def get_roc (y_test,y_pred):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #Plot of a ROC curve\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# fit, train and cross validate Decision Tree with training and test data\n",
    "def xgbclf(params, X_train, y_train,X_test, y_test):\n",
    "\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "    model = XGBClassifier(**params).\\\n",
    "      fit(X_train, y_train, eval_set=eval_set, \\\n",
    "                  eval_metric='auc', early_stopping_rounds = 100, verbose=100)\n",
    "\n",
    "    #print(model.best_ntree_limit)\n",
    "\n",
    "    model.set_params(**{'n_estimators': model.best_ntree_limit})\n",
    "    model.fit(X_train, y_train)\n",
    "    #print(model,'\\n')\n",
    "\n",
    "    # Predict target variables y for test data\n",
    "    y_pred = model.predict(X_test, ntree_limit=model.best_ntree_limit) #model.best_iteration\n",
    "    #print(y_pred)\n",
    "\n",
    "    # Get Cross Validation and Confusion matrix\n",
    "    #get_eval(model, X_train, y_train)\n",
    "    #get_eval2(model, X_train, y_train,X_test, y_test)\n",
    "\n",
    "    # Create and print confusion matrix\n",
    "    abclf_cm = confusion_matrix(y_test,y_pred)\n",
    "    print(abclf_cm)\n",
    "\n",
    "    #y_pred = model.predict(X_test)\n",
    "    print (classification_report(y_test,y_pred) )\n",
    "    print ('\\n')\n",
    "    print (\"Model Final Generalization Accuracy: %.6f\" %accuracy_score(y_test,y_pred) )\n",
    "\n",
    "    # Predict probabilities target variables y for test data\n",
    "    y_pred_proba = model.predict_proba(X_test, ntree_limit=model.best_ntree_limit)[:,1] #model.best_iteration\n",
    "    get_roc (y_test,y_pred_proba)\n",
    "    return model\n",
    "\n",
    "def plot_featureImportance(model, keys):\n",
    "    importances = model.feature_importances_\n",
    "    importance_frame = pd.DataFrame({'Importance': list(importances), 'Feature': list(keys)})\n",
    "    importance_frame.sort_values(by = 'Importance', inplace = True)\n",
    "    importance_frame.tail(10).plot(kind = 'barh', x = 'Feature', figsize = (8,8), color = 'orange')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## read dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "file = \"german.data\"\n",
    "names = ['existingchecking', 'duration', 'credithistory', 'purpose', 'creditamount',\n",
    "         'savings', 'employmentsince', 'installmentrate', 'statussex', 'otherdebtors',\n",
    "         'residencesince', 'property', 'age', 'otherinstallmentplans', 'housing',\n",
    "         'existingcredits', 'job', 'peopleliable', 'telephone', 'foreignworker', 'classification']\n",
    "data = pd.read_csv(file,names = names, delimiter=' ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## data preprocess"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Binarize the y output for easier use of e.g. ROC curves -> 0 = 'bad' credit; 1 = 'good' credit\n",
    "data.classification.replace([1,2], [1,0], inplace=True)\n",
    "# Print number of 'good' credits (should be 700) and 'bad credits (should be 300)\n",
    "data.classification.value_counts()\n",
    "\n",
    "#numerical variables labels\n",
    "numvars = ['creditamount', 'duration', 'installmentrate', 'residencesince', 'age',\n",
    "           'existingcredits', 'peopleliable', 'classification']\n",
    "\n",
    "# Standardization\n",
    "numdata_std = pd.DataFrame(StandardScaler().fit_transform(data[numvars].drop(['classification'], axis=1)))\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "#categorical variables labels\n",
    "catvars = ['existingchecking', 'credithistory', 'purpose', 'savings', 'employmentsince',\n",
    "           'statussex', 'otherdebtors', 'property', 'otherinstallmentplans', 'housing', 'job',\n",
    "           'telephone', 'foreignworker']\n",
    "\n",
    "d = defaultdict(LabelEncoder)\n",
    "\n",
    "# Encoding the variable\n",
    "lecatdata = data[catvars].apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "# print transformations\n",
    "for x in range(len(catvars)):\n",
    "    print(catvars[x],\": \", data[catvars[x]].unique())\n",
    "    print(catvars[x],\": \", lecatdata[catvars[x]].unique())\n",
    "\n",
    "#One hot encoding, create dummy variables for every category of every categorical variable\n",
    "dummyvars = pd.get_dummies(data[catvars])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## split dataset to simulate FL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Unscaled, unnormalized data\n",
    "X_clean = data_clean.drop('classification', axis=1)\n",
    "y_clean = data_clean['classification']\n",
    "# simulated 2 different party\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean,y_clean,test_size=0.2, random_state=1)\n",
    "X1_train_clean,X2_train_clean,y1_train_clean,y2_train_clean = train_test_split(X_train_clean,y_train_clean,test_size=0.5, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## simulate FL with node=2\n",
    "from numpy import average,mean\n",
    "from math import ceil\n",
    "params={}\n",
    "\n",
    "params1={\n",
    "    'n_estimators':3000,\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.05,\n",
    "    'gamma':0.1,\n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.3,\n",
    "    'min_child_weight':3,\n",
    "    'max_depth':3,\n",
    "    #'seed':1024,\n",
    "    'n_jobs' : -1\n",
    "}\n",
    "\n",
    "params2={\n",
    "    'n_estimators':3000,\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.005,\n",
    "    #'gamma':0.01,\n",
    "    'subsample':0.555,\n",
    "    'colsample_bytree':0.7,\n",
    "    'min_child_weight':3,\n",
    "    'max_depth':8,\n",
    "    #'seed':1024,\n",
    "    'n_jobs' : -1\n",
    "}\n",
    "\n",
    "params_avg = {\n",
    "    'n_estimators':int(ceil(average([params1['n_estimators'],params2['n_estimators']]))),\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': average([params1['learning_rate'],params2['learning_rate']]),\n",
    "    #'gamma':0.01,\n",
    "    'subsample':average([params1['subsample'],params2['subsample']]),\n",
    "    'colsample_bytree':average([params1['colsample_bytree'],params2['colsample_bytree']]),\n",
    "    'min_child_weight':int(ceil(average([params1['min_child_weight'],params2['min_child_weight']]))),\n",
    "    'max_depth':int(ceil(average([params1['max_depth'],params2['max_depth']]))),\n",
    "    #'seed':1024,\n",
    "    'n_jobs' : -1}\n",
    "\n",
    "xgbclf(params1, X1_train_clean, y1_train_clean, X_test_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#res node1\n",
    "xgbclf(params1, X1_train_clean, y1_train_clean, X_test_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#res node2\n",
    "xgbclf(params2, X2_train_clean, y2_train_clean, X_test_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#res node_aggregate\n",
    "xgbclf(params_avg, X2_train_clean, y2_train_clean, X_test_clean, y_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}